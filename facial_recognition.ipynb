{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***2019R2018/MC/85***"
      ],
      "metadata": {
        "id": "YTL6ihTO4LmW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nQdFPFqBCKt",
        "outputId": "cc0af24f-1d5e-4345-e4eb-42a7fa689b87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n"
      ],
      "metadata": {
        "id": "6Lf5NkNjG5M-"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dimensions of the input images\n",
        "img_width, img_height = 128, 128\n",
        "\n",
        "# Define the batch size and number of epochs\n",
        "batch_size = 32\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "mGX2uI5TBC-5"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory path for the image data\n",
        "parent_dir = '/content/drive/MyDrive/dataset'"
      ],
      "metadata": {
        "id": "tV5mmPvaJC2x"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "        rescale=1./255,        # rescale pixel values to be between 0 and 1\n",
        "        shear_range=0.2,       # randomly apply shearing transformation\n",
        "        zoom_range=0.2,        # randomly apply zoom transformation\n",
        "        horizontal_flip=True\n",
        "        )  # randomly flip images horizontally\n",
        "\n"
      ],
      "metadata": {
        "id": "aM3Nwyy2HAJp"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    parent_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True)\n",
        "\n",
        "train_data = train_generator\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u7WqPPnHBMz",
        "outputId": "3da98c91-eb7e-40d3-ed1e-d70b4243e180"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 305 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_generator = datagen.flow_from_directory(\n",
        "    parent_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True)\n",
        "\n",
        "val_data = val_generator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2whWZPgDNM3x",
        "outputId": "85a82a82-d5cc-4f44-b233-d3f56f84ddcb"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 305 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, val_data = train_test_split(train_generator, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "MYnhJSNpJOjk"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve class indices from the generator, not the list\n",
        "train_num_classes = len(train_generator.class_indices)\n",
        "train_class_labels = list(train_generator.class_indices.keys())\n",
        "print('Number of classes in training dataset:', train_num_classes)\n",
        "print('Class labels in training dataset:', train_class_labels)\n",
        "# Define the input shape of your images\n",
        "input_shape = (img_width, img_height, 3)\n",
        "\n",
        "# Define the number of classes\n",
        "num_classes = train_num_classes\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46ksArZoHKKk",
        "outputId": "ba495adf-05d3-4d5d-d9fb-1cccb6dead4b"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes in training dataset: 6\n",
            "Class labels in training dataset: ['class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Customized Architecture***"
      ],
      "metadata": {
        "id": "Z4incx0L7IEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Custom CNN model architecture\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile your model with an appropriate loss function and optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "C8KaTBHoBfa-"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on the training data\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=num_epochs,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.samples // batch_size)"
      ],
      "metadata": {
        "id": "6QDLzKzEIWqo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b518eec-a0be-4312-ec80-cb3c591ec8e6"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "9/9 [==============================] - 96s 11s/step - loss: 1.7890 - accuracy: 0.2198 - val_loss: 1.6639 - val_accuracy: 0.4826\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 128s 15s/step - loss: 1.3934 - accuracy: 0.4799 - val_loss: 0.9142 - val_accuracy: 0.5625\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 88s 10s/step - loss: 0.8599 - accuracy: 0.6923 - val_loss: 0.5177 - val_accuracy: 0.8299\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 86s 10s/step - loss: 0.5803 - accuracy: 0.7692 - val_loss: 0.3127 - val_accuracy: 0.8958\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 85s 10s/step - loss: 0.2934 - accuracy: 0.8938 - val_loss: 0.1651 - val_accuracy: 0.9479\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 86s 10s/step - loss: 0.2938 - accuracy: 0.9028 - val_loss: 0.1356 - val_accuracy: 0.9583\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 85s 10s/step - loss: 0.1698 - accuracy: 0.9524 - val_loss: 0.1032 - val_accuracy: 0.9583\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 84s 10s/step - loss: 0.1391 - accuracy: 0.9597 - val_loss: 0.1024 - val_accuracy: 0.9583\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 84s 10s/step - loss: 0.1227 - accuracy: 0.9670 - val_loss: 0.0922 - val_accuracy: 0.9688\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 85s 10s/step - loss: 0.1070 - accuracy: 0.9634 - val_loss: 0.0506 - val_accuracy: 0.9861\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f382b192a70>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation data\n",
        "val_loss, val_accuracy = model.evaluate(val_generator, steps=val_generator.samples // batch_size)\n",
        "print('Validation loss:', val_loss)\n",
        "print('Validation accuracy:', val_accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwRk6QqTMPLz",
        "outputId": "bf6f170f-c050-4ef8-af7f-8daef340c92c"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 44s 5s/step - loss: 0.0450 - accuracy: 0.9861\n",
            "Validation loss: 0.04503175616264343\n",
            "Validation accuracy: 0.9861111044883728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ezPzPdNnnCIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Alex Net***"
      ],
      "metadata": {
        "id": "ZpMtHF0KnCyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dimensions of the input images\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "# Define the batch size and number of epochs\n",
        "batch_size = 32\n",
        "num_epochs = 7"
      ],
      "metadata": {
        "id": "tQbdSU46nLh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Define your AlexNet model architecture\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(96, (11, 11), strides=(4, 4), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (5, 5), padding=\"same\", activation='relu'))\n",
        "model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(384, (3, 3), padding=\"same\", activation='relu'))\n",
        "model.add(Conv2D(384, (3, 3), padding=\"same\", activation='relu'))\n",
        "model.add(Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\n",
        "model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile your model with an appropriate loss function and optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train your model on the training data\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=num_epochs,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.samples // batch_size)\n",
        "\n",
        "# Evaluate the model on the validation data\n",
        "val_loss, val_accuracy = model.evaluate(val_generator, steps=val_generator.samples // batch_size)\n",
        "print('Validation loss:', val_loss)\n",
        "print('Validation accuracy:', val_accuracy)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P2y483jtTsY9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1a8e190-cba6-41c2-ffe5-813caf80cf7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "9/9 [==============================] - 98s 11s/step - loss: 1.9505 - accuracy: 0.1282 - val_loss: 1.7929 - val_accuracy: 0.1771\n",
            "Epoch 2/7\n",
            "9/9 [==============================] - 92s 11s/step - loss: 1.7931 - accuracy: 0.1648 - val_loss: 1.7924 - val_accuracy: 0.1632\n",
            "Epoch 3/7\n",
            "9/9 [==============================] - 89s 10s/step - loss: 1.8129 - accuracy: 0.1612 - val_loss: 1.7839 - val_accuracy: 0.1667\n",
            "Epoch 4/7\n",
            "9/9 [==============================] - 128s 15s/step - loss: 1.7930 - accuracy: 0.1685 - val_loss: 1.7912 - val_accuracy: 0.1840\n",
            "Epoch 5/7\n",
            "9/9 [==============================] - 129s 15s/step - loss: 1.7943 - accuracy: 0.1795 - val_loss: 1.7919 - val_accuracy: 0.1840\n",
            "Epoch 6/7\n",
            "9/9 [==============================] - 130s 16s/step - loss: 1.7933 - accuracy: 0.1722 - val_loss: 1.7919 - val_accuracy: 0.1736\n",
            "Epoch 7/7\n",
            "9/9 [==============================] - 128s 15s/step - loss: 1.7928 - accuracy: 0.1612 - val_loss: 1.7887 - val_accuracy: 0.1806\n",
            "9/9 [==============================] - 38s 4s/step - loss: 1.7889 - accuracy: 0.1979\n",
            "Validation loss: 1.7888692617416382\n",
            "Validation accuracy: 0.1979166716337204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***VGG-16***"
      ],
      "metadata": {
        "id": "chUitPcKnbhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dimensions of the input images\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "# Define the batch size and number of epochs\n",
        "batch_size = 32\n",
        "num_epochs = 7\n",
        "\n",
        "# Define your VGG-16 model architecture\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile your model with an appropriate loss function and optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train your model on the training data\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=num_epochs,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.samples // batch_size)\n",
        "\n",
        "# Evaluate the model on the validation data\n",
        "val_loss, val_accuracy = model.evaluate(val_generator, steps=val_generator.samples // batch_size)\n",
        "print('Validation loss:', val_loss)\n",
        "print('Validation accuracy:', val_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQyiU_nunWI4",
        "outputId": "95fc3a3a-c765-4b03-b366-c86ebf292ef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "9/9 [==============================] - 377s 43s/step - loss: 2.1696 - accuracy: 0.1502 - val_loss: 1.7965 - val_accuracy: 0.1701\n",
            "Epoch 2/7\n",
            "9/9 [==============================] - 366s 42s/step - loss: 1.7969 - accuracy: 0.1722 - val_loss: 1.7926 - val_accuracy: 0.1736\n",
            "Epoch 3/7\n",
            "9/9 [==============================] - 374s 43s/step - loss: 1.7939 - accuracy: 0.1685 - val_loss: 1.7913 - val_accuracy: 0.1806\n",
            "Epoch 4/7\n",
            "9/9 [==============================] - 367s 42s/step - loss: 1.7918 - accuracy: 0.1832 - val_loss: 1.7927 - val_accuracy: 0.1632\n",
            "Epoch 5/7\n",
            "9/9 [==============================] - 370s 44s/step - loss: 1.7933 - accuracy: 0.1575 - val_loss: 1.7915 - val_accuracy: 0.1736\n",
            "Epoch 6/7\n",
            "9/9 [==============================] - 368s 42s/step - loss: 1.7920 - accuracy: 0.1722 - val_loss: 1.7911 - val_accuracy: 0.1806\n",
            "Epoch 7/7\n",
            "9/9 [==============================] - 368s 44s/step - loss: 1.7934 - accuracy: 0.1722 - val_loss: 1.7916 - val_accuracy: 0.1806\n",
            "9/9 [==============================] - 87s 9s/step - loss: 1.7910 - accuracy: 0.1806\n",
            "Validation loss: 1.7910192012786865\n",
            "Validation accuracy: 0.1805555522441864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***LeNet***"
      ],
      "metadata": {
        "id": "ieGOpzv9629W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LeNet-5 model architecture\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(120, activation='relu'))\n",
        "model.add(Dense(84, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile your model with an appropriate loss function and optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train your model on the training data\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=num_epochs,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.samples // batch_size)\n",
        "\n",
        "# Evaluate the model on the validation data\n",
        "val_loss, val_accuracy = model.evaluate(val_generator, steps=val_generator.samples // batch_size)\n",
        "print('Validation loss:', val_loss)\n",
        "print('Validation accuracy:', val_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoiHEFwR612B",
        "outputId": "52c9e9fd-0297-4df5-a8c7-a513b1d5b72b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "9/9 [==============================] - 89s 10s/step - loss: 1.7007 - accuracy: 0.3260 - val_loss: 1.5252 - val_accuracy: 0.4375\n",
            "Epoch 2/7\n",
            "9/9 [==============================] - 84s 10s/step - loss: 1.3029 - accuracy: 0.5385 - val_loss: 0.9297 - val_accuracy: 0.7674\n",
            "Epoch 3/7\n",
            "9/9 [==============================] - 79s 9s/step - loss: 0.6981 - accuracy: 0.8388 - val_loss: 0.3833 - val_accuracy: 0.8681\n",
            "Epoch 4/7\n",
            "9/9 [==============================] - 80s 9s/step - loss: 0.3924 - accuracy: 0.8718 - val_loss: 0.3274 - val_accuracy: 0.8924\n",
            "Epoch 5/7\n",
            "9/9 [==============================] - 80s 9s/step - loss: 0.3441 - accuracy: 0.8828 - val_loss: 0.2090 - val_accuracy: 0.9410\n",
            "Epoch 6/7\n",
            "9/9 [==============================] - 79s 9s/step - loss: 0.2456 - accuracy: 0.9231 - val_loss: 0.2764 - val_accuracy: 0.9201\n",
            "Epoch 7/7\n",
            "9/9 [==============================] - 80s 10s/step - loss: 0.1676 - accuracy: 0.9414 - val_loss: 0.0889 - val_accuracy: 0.9757\n",
            "9/9 [==============================] - 37s 4s/step - loss: 0.0919 - accuracy: 0.9757\n",
            "Validation loss: 0.09188515692949295\n",
            "Validation accuracy: 0.9756944179534912\n"
          ]
        }
      ]
    }
  ]
}